{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a461ebeb-599d-4fc0-8d75-598d1c29339f",
   "metadata": {},
   "source": [
    "## 1. Pyspark 현재 사양"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77270524-0777-4ae6-99c7-d95c1062e301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스파크 컨텍스트 버젼:  3.3.4\n",
      "Spark Context 파이썬 버전: 3.9\n",
      "Spark Context 마스터: local[*]\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"SparkContext\")\n",
    "\n",
    "# SparkContext 버전\n",
    "print(\"스파크 컨텍스트 버젼: \", sc.version)\n",
    "\n",
    "# SparkContext 파이썬 버전\n",
    "print(\"Spark Context 파이썬 버전:\", sc.pythonVer)\n",
    "\n",
    "# SparkContext 마스터\n",
    "print(\"Spark Context 마스터:\", sc.master)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f26b36-47ce-495f-85c4-ce69fb118c24",
   "metadata": {},
   "source": [
    "## 2. pyspark 환경 설정 및 간단한 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a983034b-63cd-43b8-afe6-206cb2773532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "# pyspark 환경 빌드 예제\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#sparksession 드라이버 프로세스 얻기\n",
    "#클러스터모드의 경우 master에 local[*] 대신 yarn이 들어간다.\n",
    "spark = SparkSession.builder.appName(\"sample\").master(\"local[*]\").getOrCreate()\n",
    "\n",
    "#jupyter환경에서만 가능한 config, .show()메소드를 사용할 필요없이 dataframe만 실행해도,정렬된 프린팅을 해준다.\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f513a1e9-0338-4028-8cee-baab2f45a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#간단한 예제 1\n",
    "df= spark.range(500).toDF(\"number\")\n",
    "df.select(df[\"number\"]+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c1cd1c0-7588-4711-9e64-34cd0037b4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'((((someCol + 5) * 200) - 6) < otherCol)'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#간단한 예제 2\n",
    "from pyspark.sql.functions import expr\n",
    "expr(\"(((someCol + 5) * 200) - 6) < otherCol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63663388-854e-4bf4-896b-296e01302a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d64d6d-b09b-4ed5-80c3-6fbb6f35c5c5",
   "metadata": {},
   "source": [
    "## 3. json 파일 불러오기 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b73c20-883c-4b44-940b-2a9e2fadac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "sp = SparkSession.builder.appName(\"file_load\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af4ec47d-1411-45b0-8ff4-bb97aa7832f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file_path = r\"C:\\Users\\psych\\turnover.csv\"\n",
    "# # CSV 파일 읽기\n",
    "# df = sp.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "\n",
    "# # 데이터프레임 출력\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dcfac316-33b3-4203-bd2d-584d421502bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = r\"C:\\Users\\psych\\GRANDMASTER_01170808.json\"\n",
    "df1 = sp.read.json(json_file_path)\n",
    "# df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d749baa-0536-4da3-a5c9-6c1a63d0b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "350ca3fe-4158-410b-bb10-5a0c799188ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,explode\n",
    "participants_df = df1.select(col(\"mat_info.metadata.participants\"))\n",
    "# participants_df.show()\n",
    "\n",
    "\n",
    "# explode를 사용하면 배열 안의 각 요소가 별도의 행으로 분리되어 표시\n",
    "exploded_participants_df = participants_df.select(explode(\"participants\").alias(\"participant\"))\n",
    "# exploded_participants_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fea3a1-1b5c-4949-8fc3-b03946d57c04",
   "metadata": {},
   "source": [
    "### spark DF에서 데이터 추출하기\n",
    "\n",
    "row 단위로만 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "95357b93-add5-4751-84f8-246a890a6c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "\n",
    "selected_columns = [\"mat_info.info.participants.summonerName\",\"mat_info.info.participants.assists\",\"mat_info.info.participants.teamPosition\" ]\n",
    "new_df = df1.select(*selected_columns)\n",
    "summon_df = new_df.select(explode(\"summonerName\").alias(\"summonerName\"))\n",
    "summon_df = summon_df.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "# new_df.printSchema()\n",
    "# new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a0f8f122-a823-49f5-a22c-975bb18d4bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_df = new_df.select(explode(\"teamposition\").alias(\"teamposition\"))\n",
    "team_df = team_df.withColumn(\"row_id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "73d9d401-dfe3-4425-a325-866df7c766f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = summon_df.join(team_df, \"row_id\", \"inner\").drop(\"row_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "40cbc8e0-2931-4420-8272-3a8780e2040c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+\n",
      "|    summonerName|teamposition|\n",
      "+----------------+------------+\n",
      "|아름다워지고싶요|         TOP|\n",
      "|      warangurus|      JUNGLE|\n",
      "|        DK Saint|      MIDDLE|\n",
      "|        DK Rahel|      BOTTOM|\n",
      "|         용병456|     UTILITY|\n",
      "|    General irel|         TOP|\n",
      "|             Zac|      JUNGLE|\n",
      "|          쏘령관|      MIDDLE|\n",
      "|          바이탈|      BOTTOM|\n",
      "|                |     UTILITY|\n",
      "|챔프처음해도잘함|         TOP|\n",
      "|나는 멍청이 우우|      JUNGLE|\n",
      "|      쿠쿠공주님|      MIDDLE|\n",
      "|         ADC0315|      BOTTOM|\n",
      "|            neuo|     UTILITY|\n",
      "|    No teammates|         TOP|\n",
      "|    gnoeiwngonge|      JUNGLE|\n",
      "|       HLE Loki1|      MIDDLE|\n",
      "|                |      BOTTOM|\n",
      "|      비밀인간jk|     UTILITY|\n",
      "+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b574e0c6-882e-46c8-bf0c-8dfa8c188411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스파크 세션 중단\n",
    "sp.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
